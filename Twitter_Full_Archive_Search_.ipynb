{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO66JUNsTgHqpxuP9fNOIb2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnz-s/Twitter-Full-Archive-Search/blob/main/Twitter_Full_Archive_Search_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Twitter Full-Archive Search** (only Academic Research API)\n",
        "\n",
        "search the full Twitter archive for tweets containing the word \"twitter\" that were posted between January 1, 2022 and December 31, 2022, and retrieve up to 100 tweets."
      ],
      "metadata": {
        "id": "hL29kV9VGZ4a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQ7VXcUaGXmh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF2uEcq5fWNF"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Set the API endpoint and your API credentials\n",
        "endpoint = \"https://api.twitter.com/1.1/tweets/search/fullarchive/:product.json\"\n",
        "bearer_token = \"YOUR_BEARER_TOKEN\"\n",
        "\n",
        "# Set the search query and other parameters\n",
        "params = {\n",
        "    \"query\": \"twitter\",  # search for tweets containing the word \"twitter\"\n",
        "    \"maxResults\": 100,  # retrieve up to 100 tweets\n",
        "    \"fromDate\": \"2022-01-01\",  # start date for the search\n",
        "    \"toDate\": \"2022-12-31\"  # end date for the search\n",
        "}\n",
        "\n",
        "# Make the API request\n",
        "response = requests.get(endpoint, params=params, headers={\n",
        "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
        "})\n",
        "\n",
        "# Check the response status code\n",
        "if response.status_code == 200:\n",
        "    # If the request is successful, print the tweets\n",
        "    tweets = response.json()[\"data\"]\n",
        "    for tweet in tweets:\n",
        "        print(tweet[\"text\"])\n",
        "else:\n",
        "    # If the request is unsuccessful, print the error message\n",
        "    print(response.json()[\"error\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrapping more than 100 tweets:\n",
        "\n",
        "# *It will then loop through the pages of tweets, appending each page of tweets to a list, until there are no more pages of tweets to retrieve.*"
      ],
      "metadata": {
        "id": "HnWNSPNVG8V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Set the API endpoint and your API credentials\n",
        "endpoint = \"https://api.twitter.com/1.1/tweets/search/fullarchive/:product.json\"\n",
        "bearer_token = \"YOUR_BEARER_TOKEN\"\n",
        "\n",
        "# Set the search query and other parameters\n",
        "params = {\n",
        "    \"query\": \"twitter\",  # search for tweets containing the word \"twitter\"\n",
        "    \"maxResults\": 100,  # retrieve up to 100 tweets per page\n",
        "    \"fromDate\": \"2022-01-01\",  # start date for the search\n",
        "    \"toDate\": \"2022-12-31\"  # end date for the search\n",
        "}\n",
        "\n",
        "# Initialize an empty list to store the tweets\n",
        "tweets = []\n",
        "\n",
        "# Set a flag to control the loop\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    # Make the API request\n",
        "    response = requests.get(endpoint, params=params, headers={\n",
        "        \"Authorization\": f\"Bearer {bearer_token}\"\n",
        "    })\n",
        "\n",
        "    # Check the response status code\n",
        "    if response.status_code == 200:\n",
        "        # If the request is successful, append the tweets to the list\n",
        "        new_tweets = response.json()[\"data\"]\n",
        "        tweets.extend(new_tweets)\n",
        "\n",
        "        # Check if there are more pages of tweets\n",
        "        if \"next\" in response.json():\n",
        "            # If there are more pages, update the URL for the next page\n",
        "            params[\"next\"] = response.json()[\"next\"]\n",
        "        else:\n",
        "            # If there are no more pages, set the flag to True to exit the loop\n",
        "            done = True\n",
        "    else:\n",
        "        # If the request is unsuccessful, print the error message\n",
        "        print(response.json()[\"error\"])\n",
        "\n",
        "# Print the total number of tweets\n",
        "print(len(tweets))"
      ],
      "metadata": {
        "id": "OBrJaSj_G_CG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}